{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsteman/textifai/blob/main/PDF_to_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pas6buKfTXzs",
        "outputId": "8322992d-fc34-4bc6-a24c-f8c45b34b5e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
            "Collecting layoutparser\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymupdf\n",
            "  Downloading PyMuPDF-1.22.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from layoutparser) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from layoutparser) (4.7.0.72)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser) (1.5.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from layoutparser) (6.0)\n",
            "Collecting iopath (from layoutparser)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser)\n",
            "  Downloading pdfplumber-0.9.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m878.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser) (4.65.0)\n",
            "Collecting portalocker (from iopath->layoutparser)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser) (2022.7.1)\n",
            "Collecting pdfminer.six==20221105 (from pdfplumber->layoutparser)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow (from pdf2image)\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Wand>=0.6.10 (from pdfplumber->layoutparser)\n",
            "  Downloading Wand-0.6.11-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber->layoutparser) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber->layoutparser) (40.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->layoutparser) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->layoutparser) (2.21)\n",
            "Building wheels for collected packages: iopath\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=aa254cfa6bbb7993c2959b820edc6ff48666d905a0cb437a149b2e1980d879ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built iopath\n",
            "Installing collected packages: Wand, pymupdf, portalocker, pillow, pdf2image, iopath, pdfminer.six, pdfplumber, layoutparser\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "Successfully installed Wand-0.6.11 iopath-0.1.10 layoutparser-0.3.4 pdf2image-1.16.3 pdfminer.six-20221105 pdfplumber-0.9.0 pillow-9.5.0 portalocker-2.7.0 pymupdf-1.22.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting detectron2\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision v0.5) to /tmp/pip-install-9fz34rwc/detectron2_9e3c6ff38f6741b591b0f04e5fc101f6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-install-9fz34rwc/detectron2_9e3c6ff38f6741b591b0f04e5fc101f6\n",
            "  Running command git checkout -q 82a57ce0b70057685962b352535147d9a8118578\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 82a57ce0b70057685962b352535147d9a8118578\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2) (9.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2) (2.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2) (2.3.0)\n",
            "Collecting yacs>=0.1.6 (from detectron2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2) (4.65.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2) (2.12.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2) (0.18.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2) (1.4.2)\n",
            "Collecting omegaconf>=2.1 (from detectron2)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==21.4b2 (from detectron2)\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2) (8.1.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2) (2022.10.31)\n",
            "Collecting pathspec<1,>=0.8.1 (from black==21.4b2->detectron2)\n",
            "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==21.4b2->detectron2)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (6.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2) (23.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.5-cp310-cp310-linux_x86_64.whl size=7738367 sha256=530e901b5edc2e796c11fd85b9d6212e36cd6f4175475424029936e4b2ffd8f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dicsh5so/wheels/90/18/04/b8a1ce45720c57c3fa0364dc489ef160ee2136361e994d3e81\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=a8078d48ee01808042476afdc6393e5093c88c203ce7e4db7c532cafee1c2192\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=dea9c93ee43be603f3abaf060609ff4972de414bad9dd406ffee92dd1a52ae1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: iopath\n",
            "    Found existing installation: iopath 0.1.10\n",
            "    Uninstalling iopath-0.1.10:\n",
            "      Successfully uninstalled iopath-0.1.10\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-21.4b2 detectron2-0.5 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.11.1 yacs-0.1.8\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 174 kB of archives.\n",
            "After this operation, 754 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.1 [174 kB]\n",
            "Fetched 174 kB in 1s (117 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.86.1-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Setting up poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install pdf2image layoutparser pymupdf torchvision && pip install \"git+https://github.com/facebookresearch/detectron2.git@v0.5#egg=detectron2\"\t\n",
        "!apt-get install poppler-utils "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZEThjEX1htt"
      },
      "outputs": [],
      "source": [
        "import pdf2image\n",
        "import numpy as np\n",
        "import layoutparser as lp\n",
        "import fitz\n",
        "import time\n",
        "import sys\n",
        "import re\n",
        "import os\n",
        "import collections\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS-bjnE02Ons"
      },
      "outputs": [],
      "source": [
        "pdf_file = 'TextRank Bringing Order into Texts.pdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpmaJrDccocU"
      },
      "outputs": [],
      "source": [
        "doc = fitz.open(pdf_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-ye7u5wctQc"
      },
      "outputs": [],
      "source": [
        "pages = doc.page_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69LpqxrE6JmF",
        "outputId": "4d754a4e-fc79-402b-ba00-ebe34d67fb6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "config.yaml?dl=1: 8.19kB [00:02, 2.89kB/s]\n",
            "model_final.pth?dl=1: 856MB [00:57, 15.0MB/s]                           \n",
            "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
            "  proposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\n"
          ]
        }
      ],
      "source": [
        "model = lp.Detectron2LayoutModel('lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config',\n",
        "                                 extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.8],\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUrm72pu6ORv"
      },
      "outputs": [],
      "source": [
        "model.label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kasXxtmjGNXr",
        "outputId": "1ad66ee5-5d6e-45f5-806e-8c56a30623e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "%pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqwyzvpnP4Ub",
        "outputId": "bbb30206-8e40-4cf8-a8e1-36b1db8f9fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Front page: True\n",
            "Front page: True\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import spacy\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Load the small English model in spaCy\n",
        "# You need to install spaCy and download the model: pip install spacy && python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def is_front_page(text):\n",
        "    # Patterns to search for in the text\n",
        "    title_pattern = re.compile(r'\\btitle\\b', re.IGNORECASE)\n",
        "    author_pattern = re.compile(r'\\bauthor(s)?\\b', re.IGNORECASE)\n",
        "    abstract_pattern = re.compile(r'\\babstract\\b', re.IGNORECASE)\n",
        "\n",
        "    # Check if the patterns are found in the text\n",
        "    has_title = bool(title_pattern.search(text))\n",
        "    has_author = bool(author_pattern.search(text))\n",
        "    has_abstract = bool(abstract_pattern.search(text))\n",
        "\n",
        "    # Analyze text with spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Check for common entities found on front pages\n",
        "    has_person = any([ent.label_ == \"PERSON\" for ent in doc.ents])\n",
        "    has_org = any([ent.label_ == \"ORG\" for ent in doc.ents])\n",
        "\n",
        "    # Classify as front page if at least two of the patterns are found, or if it has person and organization entities\n",
        "    return ((has_title and has_author) or (has_title and has_abstract) or (has_author and has_abstract)) or (has_person and has_org)\n",
        "\n",
        "# Example 1 usage\n",
        "pdf_file1 = 'Textrank Bringing Order into Texts.pdf'\n",
        "with open(pdf_file1, 'rb') as f:\n",
        "    # Extract text from the first page of the PDF\n",
        "    reader = PdfReader(f)\n",
        "    first_page = reader.pages[0]\n",
        "    first_page_text = first_page.extract_text()\n",
        "\n",
        "    # Check if it's a front page\n",
        "    is_front = is_front_page(first_page_text)\n",
        "    print('Front page:', is_front)\n",
        "\n",
        "# Example 2 usage\n",
        "pdf_file2 = 'MASTERING DIGITAL.pdf'\n",
        "with open(pdf_file2, 'rb') as f:\n",
        "    # Extract text from the first page of the PDF\n",
        "    reader = PdfReader(f)\n",
        "    first_page = reader.pages[0]\n",
        "    first_page_text = first_page.extract_text()\n",
        "\n",
        "    # Check if it's a front page\n",
        "    is_front = is_front_page(first_page_text)\n",
        "    print('Front page:', is_front)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0KNxiXwQG6Q",
        "outputId": "5fd77f4e-e419-4259-c4bc-677b760d7886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Front page: False\n"
          ]
        }
      ],
      "source": [
        "with open(pdf_file, 'rb') as f:\n",
        "    # Extract text from the first page of the PDF\n",
        "    # You need to install PyPDF2 for this: pip install PyPDF2\n",
        "    import PyPDF2\n",
        "\n",
        "    reader = PyPDF2.PdfReader(f)\n",
        "    first_page = reader.pages[0]\n",
        "    first_page_text = first_page.extract_text()\n",
        "\n",
        "    # Check if it's a front page\n",
        "    is_front = is_front_page(first_page_text)\n",
        "    print('Front page:', is_front)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34GUCyZ48KyE"
      },
      "outputs": [],
      "source": [
        "def analyze_pdf_columns(file_path):\n",
        "    \"\"\"\n",
        "    Analyzes the layout of a PDF file to determine the number of columns on the first page.\n",
        "    \n",
        "    Args:\n",
        "        file_path (str): The path to the PDF file.\n",
        "    \n",
        "    Returns:\n",
        "        int: The number of columns detected on the first page of the PDF.\n",
        "    \"\"\"\n",
        "    \n",
        "    doc = fitz.open(file_path)\n",
        "    page = doc.load_page(1)  # analyze the first page\n",
        "    blocks = page.get_text(\"blocks\")\n",
        "    \n",
        "    # Group text blocks by their vertical positions\n",
        "    y_positions = collections.defaultdict(list)\n",
        "    for block in blocks:\n",
        "        x0, y0, x1, y1, *_ = block\n",
        "        y_positions[int(y0)].append(block)\n",
        "    \n",
        "    # Count the number of columns based on the number of text blocks in each horizontal line\n",
        "    columns_count = max([len(y_positions[key]) for key in y_positions])\n",
        "\n",
        "    return columns_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqHdC3SG2RcJ"
      },
      "outputs": [],
      "source": [
        "def convert_dpi_to_coordinates(dpi, target_size):\n",
        "    \n",
        "    \"\"\"\n",
        "    Converts DPI values to corresponding scale factors and margins for resizing coordinates.\n",
        "    \n",
        "    Args:\n",
        "        dpi (tuple): A tuple containing the DPI values for the x and y axes (width, height).\n",
        "        target_size (tuple): A tuple containing the target size of the output image (width, height).\n",
        "    \n",
        "    Returns:\n",
        "        tuple: A tuple containing the x_margin, y_margin, x_scale, and y_scale values.\n",
        "    \"\"\"\n",
        "\n",
        "    x_margin = target_size[0]/100*1\n",
        "    y_margin = target_size[0]/100*1\n",
        "\n",
        "    x_scale = target_size[0] / dpi[0]\n",
        "    y_scale = target_size[1] / dpi[1]\n",
        "    \n",
        "    return x_margin, y_margin, x_scale, y_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBPcf3ssQAef"
      },
      "outputs": [],
      "source": [
        "def convert_and_scale_coordinates(dpi, target_size, text_blocks):\n",
        "    \"\"\"\n",
        "    Converts DPI values to corresponding scale factors and margins for resizing coordinates and scales the coordinates.\n",
        "    \n",
        "    Args:\n",
        "        dpi (tuple): A tuple containing the DPI values for the x and y axes (width, height).\n",
        "        target_size (tuple): A tuple containing the target size of the output image (width, height).\n",
        "        text_blocks (list): A list of text blocks with coordinates.\n",
        "    \n",
        "    Returns:\n",
        "        list: A list of tuples containing the scaled coordinates.\n",
        "    \"\"\"\n",
        "    x_margin = target_size[0]/100*1\n",
        "    y_margin = target_size[0]/100*1\n",
        "\n",
        "    x_scale = target_size[0] / dpi[0]\n",
        "    y_scale = target_size[1] / dpi[1]\n",
        "    \n",
        "    # Resize coordinates and margins\n",
        "    print(\"===== Convert coordinates ====\")\n",
        "    x_margin, y_margin, x_scale, y_scale = convert_dpi_to_coordinates(dpi, target_size)\n",
        "\n",
        "    scaled_coordinates = []\n",
        "\n",
        "    for block in text_blocks:\n",
        "        c = block.block.coordinates\n",
        "        scaled_coordinates.append((c[0]*x_scale-x_margin, c[1]*y_scale-y_margin, c[2]*x_scale+x_margin, c[3]*y_scale+y_margin))\n",
        "    \n",
        "    return scaled_coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yqGnp_ynsQL"
      },
      "outputs": [],
      "source": [
        "def process_text_fields(layout_result, img, img_width):\n",
        "    \"\"\"\n",
        "    Process text fields from a layout result and sort them based on their position on the page.\n",
        "\n",
        "    Args:\n",
        "        layout_result (lp.Layout): A layout result object containing the layout data.\n",
        "        img_width (int): The width of the image.\n",
        "\n",
        "    Returns:\n",
        "        lp.Layout: A layout object containing the processed and sorted text blocks.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Extract and process Text fields\n",
        "    text_blocks = lp.Layout([b for b in layout_result if b.type == 'Text'])\n",
        "\n",
        "    left_interval = lp.Interval(0, img_width / 2 * 1.05, axis='x').put_on_canvas(img)\n",
        "\n",
        "    left_blocks = text_blocks.filter_by(left_interval, center=True)\n",
        "    left_blocks.sort(key=lambda b: b.coordinates[1], inplace=True)\n",
        "\n",
        "    right_blocks = lp.Layout([b for b in text_blocks if b not in left_blocks])\n",
        "    right_blocks.sort(key=lambda b: b.coordinates[1], inplace=True)\n",
        "\n",
        "    # Combine the two lists and add the index\n",
        "    text_blocks = lp.Layout([b.set(id=idx) for idx, b in enumerate(left_blocks + right_blocks)])\n",
        "\n",
        "    return text_blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDPsjdHM3L_n"
      },
      "outputs": [],
      "source": [
        "def get_text_from_pdf(page, model=model, pdf=pdf_file):  \n",
        "    \n",
        "    \"\"\"\n",
        "    Extracts text from a specified PDF page using a given layout detection model.\n",
        "    \n",
        "    Args:\n",
        "        page (int): The page number to extract text from.\n",
        "        model: The layout detection model.\n",
        "        pdf_path (str): The path to the PDF file.\n",
        "        dpi (tuple): The DPI of the input image (default: (1700, 2200)).\n",
        "        target_size (tuple): The target size of the PDF page (default: (612, 792)).\n",
        "    \n",
        "    Returns:\n",
        "        list: A list of extracted text blocks.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Load specified page\n",
        "    p = doc.load_page(page) \n",
        "    # PDF Size\n",
        "    pdf_h, pdf_w = p.rect.width, p.rect.height\n",
        "    \n",
        "    # Convert PDF to IMG\n",
        "    print(\"===== Convert page to img ====\")\n",
        "    img = np.asarray(pdf2image.convert_from_path(pdf_path=pdf)[page])\n",
        "    # DPI Dimensions \n",
        "    img_h, img_w = img.shape[:2]\n",
        "    \n",
        "    # Document Layout Analysis to extract Text fields only\n",
        "    print(\"===== Run LayoutDetection Model ====\")\n",
        "    layout_result = model.detect(img)\n",
        "    print(\"===== Finished LayoutDetection Model ====\")\n",
        "\n",
        "    # Extract text blocks\n",
        "    text_blocks = process_text_fields(layout_result=layout_result, img=img, img_width=img_w)\n",
        "\n",
        "    # Resize coordinates and margins\n",
        "    print(\"===== Convert coordinates ====\")\n",
        "\n",
        "    scaled_coordinates = convert_and_scale_coordinates(dpi=(1700, 2200), target_size=(612, 792), text_blocks=text_blocks)\n",
        "\n",
        "    # Extract Text blocks\n",
        "    print(\"===== Extract text ====\")\n",
        "\n",
        "    text = []\n",
        "\n",
        "    for sc in scaled_coordinates:\n",
        "        rct = fitz.Rect(sc)\n",
        "        txt = p.get_textbox(rct)\n",
        "        text.append(txt)  \n",
        "    \n",
        "    print(\"===== Done ====\")\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_JyKl2GZZ1x"
      },
      "outputs": [],
      "source": [
        "def get_pdf_dimensions(pdf_file_path):\n",
        "    \"\"\"\n",
        "    Get the height and width of a PDF file using the PyMuPDF library.\n",
        "\n",
        "    Args:\n",
        "        pdf_file_path (str): The path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the width and height of the PDF file.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_file_path)\n",
        "    page = doc.load_page(0)  # Load the first page of the document\n",
        "    width, height = page.rect.width, page.rect.height\n",
        "    doc.close()\n",
        "\n",
        "    return width, height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTRmXUwSqz3g"
      },
      "outputs": [],
      "source": [
        "def parallel_extract_text(num_processes=None):\n",
        "    \"\"\"\n",
        "    Extract text from each page of a PDF file in parallel using multiprocessing.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file to be processed.\n",
        "        num_processes (int, optional): Number of processes to use. Defaults to the number of available CPU cores.\n",
        "\n",
        "    Returns:\n",
        "        list: Extracted text from each page of the PDF in the order they appear.\n",
        "    \"\"\"\n",
        "    global pdf_file\n",
        "\n",
        "    with fitz.open(pdf_file) as doc:\n",
        "        num_pages = doc.page_count\n",
        "\n",
        "    if num_processes is None:\n",
        "        num_processes = multiprocessing.cpu_count()\n",
        "\n",
        "    # Create a temporary file to avoid opening the PDF file multiple times\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
        "        tmp_file.write(open(pdf_file, 'rb').read())\n",
        "        tmp_pdf_path = tmp_file.name\n",
        "\n",
        "    try:\n",
        "        with multiprocessing.Pool(processes=num_processes) as pool:\n",
        "            # Process each page in parallel\n",
        "            results = pool.map(get_text_from_pdf, [(tmp_pdf_path, i, model) for i in range(num_pages)])\n",
        "    finally:\n",
        "        os.unlink(tmp_pdf_path)  # Remove the temporary file\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "H23Z2Ar3dcvP",
        "outputId": "cd723ed4-cc11-46cd-f827-eaa422cf6afe"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-13-a1a3c871f96b>\", line 18, in get_text_from_pdf\n    p = doc.load_page(page)\n  File \"/usr/local/lib/python3.9/dist-packages/fitz/fitz.py\", line 4024, in load_page\n    raise ValueError(\"page not in document\")\nValueError: page not in document\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0fff60f13155>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparallel_extract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-3d5e74d7f9a5>\u001b[0m in \u001b[0;36mparallel_extract_text\u001b[0;34m(num_processes)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_processes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# Process each page in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_text_from_pdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_pdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_pages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_pdf_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove the temporary file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: page not in document"
          ]
        }
      ],
      "source": [
        "parallel_extract_text(num_processes=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O48-LiMiDLVx",
        "outputId": "5758011e-a438-4878-fd93-d10a733d67c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n",
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n",
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n",
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n",
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n",
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n",
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "===== Convert page to img ====\n",
            "===== Run LayoutDetection Model ====\n",
            "===== Finished LayoutDetection Model ====\n",
            "===== Convert coordinates ====\n",
            "===== Convert coordinates ====\n",
            "===== Extract text ====\n",
            "===== Done ====\n",
            "Operation took 15.725383520126343 seconds\n"
          ]
        }
      ],
      "source": [
        "s = time.time()\n",
        "text = []\n",
        "\n",
        "for page in range(pages):\n",
        "  text.append(get_text_from_pdf(page))\n",
        "\n",
        "e = time.time()\n",
        "\n",
        "print(f\"Operation took {e-s} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caM6_DSjNoa7",
        "outputId": "3f57d2b8-0b8b-4d9a-de7b-2305246ab32d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['Rada Mihalcea and Paul Tarau\\nDepartment of Computer Science\\nUniversity of North Texas\\n� rada,tarau\\n� @cs.unt.edu',\n",
              "  'Abstract\\nIn this paper, we introduce TextRank – a graph-based\\nranking model for text processing, and show how this\\nmodel can be successfully used in natural language\\napplications. In particular, we propose two innova-\\ntive unsupervised methods for keyword and sentence\\nextraction, and show that the results obtained com-\\npare favorably with previously published results on\\nestablished benchmarks.',\n",
              "  '1\\nIntroduction\\nGraph-based ranking algorithms like Kleinberg’s\\nHITS algorithm (Kleinberg,\\n1999) or Google’s\\nPageRank (Brin and Page, 1998) have been success-\\nfully used in citation analysis, social networks, and\\nthe analysis of the link-structure of the World Wide\\nWeb. Arguably, these algorithms can be singled out\\nas key elements of the paradigm-shift triggered in\\nthe field of Web search technology, by providing a\\nWeb page ranking mechanism that relies on the col-\\nlective knowledge of Web architects rather than in-\\ndividual content analysis of Web pages. In short, a\\ngraph-based ranking algorithm is a way of deciding\\non the importance of a vertex within a graph, by tak-\\ning into account global information recursively com-\\nputed from the entire graph, rather than relying only\\non local vertex-specific information.\\nApplying a similar line of thinking to lexical',\n",
              "  'on local vertex-specific information.\\nApplying a similar line of thinking to lexical\\nor semantic graphs extracted from natural language\\ndocuments, results in a graph-based ranking model\\nthat can be applied to a variety of natural language\\nprocessing applications, where knowledge drawn\\nfrom an entire text is used in making local rank-\\ning/selection decisions. Such text-oriented ranking\\nmethods can be applied to tasks ranging from auto-\\nmated extraction of keyphrases, to extractive summa-\\nrization and word sense disambiguation (Mihalcea et\\nal., 2004).\\nIn this paper, we introduce the TextRank graph-',\n",
              "  'al., 2004).\\nIn this paper, we introduce the TextRank graph-\\nbased ranking model for graphs extracted from nat-\\nural language texts. We investigate and evaluate the\\napplication of TextRank to two language processing\\ntasks consisting of unsupervised keyword and sen-',\n",
              "  'tence extraction, and show that the results obtained\\nwith TextRank are competitive with state-of-the-art\\nsystems developed in these areas.',\n",
              "  '2\\nThe TextRank Model\\nGraph-based ranking algorithms are essentially a\\nway of deciding the importance of a vertex within\\na graph, based on global information recursively\\ndrawn from the entire graph.\\nThe basic idea im-\\nplemented by a graph-based ranking model is that\\nof “voting” or “recommendation”. When one ver-\\ntex links to another one, it is basically casting a vote\\nfor that other vertex. The higher the number of votes\\nthat are cast for a vertex, the higher the importance\\nof the vertex. Moreover, the importance of the vertex\\ncasting the vote determines how important the vote\\nitself is, and this information is also taken into ac-\\ncount by the ranking model. Hence, the score asso-\\nciated with a vertex is determined based on the votes\\nthat are cast for it, and the score of the vertices cast-\\ning these votes.\\nFormally, let\\n���������� be a directed graph with',\n",
              "  'ing these votes.\\nFormally, let\\nthe set of vertices���������� be a directed graph with\\n�\\nand set of edges\\n� , where\\n�\\nis a\\nsubset of\\n����� . For a given vertex\\n��� , let\\n���������� be\\nthe set of vertices that point to it (predecessors), and\\nlet\\n��������\\n�\\n� be the set of vertices that vertex\\n�\\n� points\\nto (successors). The score of a vertex\\n�\\n� is defined as\\nfollows (Brin and Page, 1998):',\n",
              "  '46587�9.:<;�=?>\\n@\\nwhere\\nL is a damping factor that can be set between\\n0 and 1, which has the role of integrating into the\\nmodel the probability of jumping from a given vertex\\nto another random vertex in the graph. In the context\\nof Web surfing, this graph-based ranking algorithm\\nimplements the “random surfer model”, where a user\\nclicks on links at random with a probability\\nL , and\\njumps to a completely new page with probability\\nMON\\nL . The factor\\nL is usually set to 0.85 (Brin and Page,\\n1998), and this is the value we are also using in our\\nimplementation.'],\n",
              " ['Starting from arbitrary values assigned to each\\nnode in the graph, the computation iterates until con-\\nvergence below a given threshold is achieved 1. After\\nrunning the algorithm, a score is associated with each\\nvertex, which represents the “importance” of the ver-\\ntex within the graph.\\nNotice that the final values\\nobtained after TextRank runs to completion are not\\naffected by the choice of the initial value, only the\\nnumber of iterations to convergence may be differ-\\nent.\\nIt is important to notice that although the TextRank',\n",
              "  'ent.\\nIt is important to notice that although the TextRank\\napplications described in this paper rely on an al-\\ngorithm derived from Google’s PageRank (Brin and\\nPage, 1998), other graph-based ranking algorithms\\nsuch as e.g. HITS (Kleinberg, 1999) or Positional\\nFunction (Herings et al., 2001) can be easily inte-\\ngrated into the TextRank model (Mihalcea, 2004).',\n",
              "  '2.1\\nUndirected Graphs\\nAlthough traditionally applied on directed graphs, a\\nrecursive graph-based ranking algorithm can be also\\napplied to undirected graphs, in which case the out-\\ndegree of a vertex is equal to the in-degree of the ver-\\ntex. For loosely connected graphs, with the number\\nof edges proportional with the number of vertices,\\nundirected graphs tend to have more gradual conver-\\ngence curves.\\nFigure 1 plots the convergence curves for a ran-',\n",
              "  'gence curves.\\nFigure 1 plots the convergence curves for a ran-\\ndomly generated graph with 250 vertices and 250\\nedges, for a convergence threshold of 0.0001. As the\\nconnectivity of the graph increases (i.e. larger num-\\nber of edges), convergence is usually achieved after\\nfewer iterations, and the convergence curves for di-\\nrected and undirected graphs practically overlap.',\n",
              "  '2.2\\nWeighted Graphs\\nIn the context of Web surfing, it is unusual for a\\npage to include multiple or partial links to another\\npage, and hence the original PageRank definition for\\ngraph-based ranking is assuming unweighted graphs.\\nHowever, in our model the graphs are build from',\n",
              "  'graph-based ranking is assuming unweighted graphs.\\nHowever, in our model the graphs are build from\\nnatural language texts, and may include multiple or\\npartial links between the units (vertices) that are ex-\\ntracted from text. It may be therefore useful to in-\\ndicate and incorporate into the model the “strength”\\nof the connection between two vertices\\n�\\n� and\\n�� as\\na weight\\n�\\n�\\n� added to the corresponding edge that\\nconnects the two vertices.',\n",
              "  '�\\n1Convergence is achieved when the error rate for any vertex\\nin the graph falls below a given threshold. The error rate of a\\nvertex\\n\"\\n$ is defined as the difference between the “real” score of\\nthe vertex\\n�K #\"%$?& and the score computed at iteration\\n� ,\\n��\\n #\"%$#& .\\nSince the real score is not known apriori, this error rate is ap-\\nproximated with the difference between the scores computed at\\ntwo successive iterations:\\n���\\n@\\n #\"%$#&\\n+0��. #\"%$#& .',\n",
              "  'Figure 1:\\nConvergence curves for graph-based\\nranking: directed/undirected, weighted/unweighted\\ngraph, 250 vertices, 250 edges.',\n",
              "  'Consequently, we introduce a new formula for\\ngraph-based ranking that takes into account edge\\nweights when computing the score associated with\\na vertex in the graph. Notice that a similar formula\\ncan be defined to integrate vertex weights.',\n",
              "  ';\\nH\\n587�9.:<;�=?>\\n3\\n���������������\\nH��\\n�\\nH\\n4\\nFigure 1 plots the convergence curves for the same\\nsample graph from section 2.1, with random weights\\nin the interval 0–10 added to the edges. While the fi-\\nnal vertex scores (and therefore rankings) differ sig-\\nnificantly as compared to their unweighted alterna-\\ntives, the number of iterations to convergence and the\\nshape of the convergence curves is almost identical\\nfor weighted and unweighted graphs.',\n",
              "  '2.3\\nText as a Graph\\nTo enable the application of graph-based ranking\\nalgorithms to natural language texts, we have to\\nbuild a graph that represents the text, and intercon-\\nnects words or other text entities with meaningful\\nrelations.\\nDepending on the application at hand,\\ntext units of various sizes and characteristics can be\\nadded as vertices in the graph, e.g. words, colloca-\\ntions, entire sentences, or others. Similarly, it is the\\napplication that dictates the type of relations that are\\nused to draw connections between any two such ver-\\ntices, e.g. lexical or semantic relations, contextual\\noverlap, etc.\\nRegardless of the type and characteristics of the el-',\n",
              "  'overlap, etc.\\nRegardless of the type and characteristics of the el-\\nements added to the graph, the application of graph-\\nbased ranking algorithms to natural language texts\\nconsists of the following main steps:'],\n",
              " ['cisions.\\nIn the following, we investigate and evaluate the\\napplication of TextRank to two natural language pro-\\ncessing tasks involving ranking of text units: (1) A\\nkeyword extraction task, consisting of the selection\\nof keyphrases representative for a given text; and (2)\\nA sentence extraction task, consisting of the identi-\\nfication of the most “important” sentences in a text,\\nwhich can be used to build extractive summaries.',\n",
              "  '3\\nKeyword Extraction\\nThe task of a keyword extraction application is to au-\\ntomatically identify in a text a set of terms that best\\ndescribe the document. Such keywords may consti-\\ntute useful entries for building an automatic index for\\na document collection, can be used to classify a text,\\nor may serve as a concise summary for a given doc-\\nument. Moreover, a system for automatic identifica-\\ntion of important terms in a text can be used for the\\nproblem of terminology extraction, and construction\\nof domain-specific dictionaries.\\nThe simplest possible approach is perhaps to use',\n",
              "  'of domain-specific dictionaries.\\nThe simplest possible approach is perhaps to use\\na frequency criterion to select the “important” key-\\nwords in a document.\\nHowever, this method was\\ngenerally found to lead to poor results, and conse-\\nquently other methods were explored. The state-of-\\nthe-art in this area is currently represented by super-\\nvised learning methods, where a system is trained to\\nrecognize keywords in a text, based on lexical and\\nsyntactic features. This approach was first suggested\\nin (Turney, 1999), where parametrized heuristic rules\\nare combined with a genetic algorithm into a sys-\\ntem for keyphrase extraction - GenEx - that automat-\\nically identifies keywords in a document. A different\\nlearning algorithm was used in (Frank et al., 1999),\\nwhere a Naive Bayes learning scheme is applied on\\nthe document collection, with improved results ob-\\nserved on the same data set as used in (Turney, 1999).\\nNeither Turney nor Frank report on the recall of\\ntheir systems, but only on precision: a 29.0% preci-\\nsion is achieved with GenEx (Turney, 1999) for five\\nkeyphrases extracted per document, and 18.3% pre-\\ncision achieved with Kea (Frank et al., 1999) for fif-\\nteen keyphrases per document.\\nMore recently, (Hulth, 2003) applies a super-',\n",
              "  'teen keyphrases per document.\\nMore recently, (Hulth, 2003) applies a super-\\nvised learning system to keyword extraction from ab-',\n",
              "  'stracts, using a combination of lexical and syntactic\\nfeatures, proved to improve significantly over previ-\\nously published results. As Hulth suggests, keyword\\nextraction from abstracts is more widely applicable\\nthan from full texts, since many documents on the\\nInternet are not available as full-texts, but only as\\nabstracts. In her work, Hulth experiments with the\\napproach proposed in (Turney, 1999), and a new ap-\\nproach that integrates part of speech information into\\nthe learning process, and shows that the accuracy of\\nthe system is almost doubled by adding linguistic\\nknowledge to the term representation.\\nIn this section, we report on our experiments in',\n",
              "  'knowledge to the term representation.\\nIn this section, we report on our experiments in\\nkeyword extraction using TextRank, and show that\\nthe graph-based ranking model outperforms the best\\npublished results in this problem. Similar to (Hulth,\\n2003), we are evaluating our algorithm on keyword\\nextraction from abstracts, mainly for the purpose of\\nallowing for a direct comparison with the results she\\nreports with her keyphrase extraction system. Notice\\nthat the size of the text is not a limitation imposed\\nby our system, and similar results are expected with\\nTextRank applied on full-texts.\\n3.1\\nTextRank for Keyword Extraction',\n",
              "  '3.1\\nTextRank for Keyword Extraction\\nThe expected end result for this application is a set of\\nwords or phrases that are representative for a given\\nnatural language text.\\nThe units to be ranked are\\ntherefore sequences of one or more lexical units ex-\\ntracted from text, and these represent the vertices that\\nare added to the text graph. Any relation that can\\nbe defined between two lexical units is a potentially\\nuseful connection (edge) that can be added between\\ntwo such vertices. We are using a co-occurrence re-\\nlation, controlled by the distance between word oc-\\ncurrences: two vertices are connected if their corre-\\nsponding lexical units co-occur within a window of\\nmaximum\\n�\\nwords, where\\n�\\ncan be set anywhere\\nfrom 2 to 10 words.\\nCo-occurrence links express\\nrelations between syntactic elements, and similar to\\nthe semantic links found useful for the task of word\\nsense disambiguation (Mihalcea et al., 2004), they\\nrepresent cohesion indicators for a given text.\\nThe vertices added to the graph can be restricted',\n",
              "  'represent cohesion indicators for a given text.\\nThe vertices added to the graph can be restricted\\nwith syntactic filters, which select only lexical units\\nof a certain part of speech. One can for instance con-\\nsider only nouns and verbs for addition to the graph,\\nand consequently draw potential edges based only on\\nrelations that can be established between nouns and\\nverbs. We experimented with various syntactic fil-\\nters, including: all open class words, nouns and verbs\\nonly, etc., with best results observed for nouns and\\nadjectives only, as detailed in section 3.2.\\nThe TextRank keyword extraction algorithm is',\n",
              "  'adjectives only, as detailed in section 3.2.\\nThe TextRank keyword extraction algorithm is\\nfully unsupervised, and proceeds as follows. First,'],\n",
              " ['Compatibility of systems of linear constraints over the set of natural numbers. \\nCriteria of compatibility of a system of linear Diophantine equations, strict\\ninequations, and nonstrict inequations are considered. Upper bounds for\\ncomponents of a minimal set of solutions and algorithms of construction of\\nminimal generating sets of solutions for all types of systems are given. \\nThese criteria and the corresponding algorithms for constructing a minimal\\nsupporting set of solutions can be used in solving all the considered  types\\nsystems and systems of mixed types.',\n",
              "  'the text is tokenized, and annotated with part of\\nspeech tags – a preprocessing step required to enable\\nthe application of syntactic filters. To avoid exces-\\nsive growth of the graph size by adding all possible\\ncombinations of sequences consisting of more than\\none lexical unit (ngrams), we consider only single\\nwords as candidates for addition to the graph, with\\nmulti-word keywords being eventually reconstructed\\nin the post-processing phase.\\nNext, all lexical units that pass the syntactic filter',\n",
              "  'in the post-processing phase.\\nNext, all lexical units that pass the syntactic filter\\nare added to the graph, and an edge is added between\\nthose lexical units that co-occur within a window of\\n�\\nwords. After the graph is constructed (undirected\\nunweighted graph), the score associated with each\\nvertex is set to an initial value of 1, and the ranking\\nalgorithm described in section 2 is run on the graph\\nfor several iterations until it converges – usually for\\n20-30 iterations, at a threshold of 0.0001.\\nOnce a final score is obtained for each vertex in the',\n",
              "  '20-30 iterations, at a threshold of 0.0001.\\nOnce a final score is obtained for each vertex in the\\ngraph, vertices are sorted in reversed order of their\\nscore, and the top\\n�\\nvertices in the ranking are re-\\ntained for post-processing. While\\n�\\nmay be set to\\nany fixed value, usually ranging from 5 to 20 key-\\nwords (e.g. (Turney, 1999) limits the number of key-\\nwords extracted with his GenEx system to five), we\\nare using a more flexible approach, which decides',\n",
              "  'the number of keywords based on the size of the text.\\nFor the data used in our experiments, which consists\\nof relatively short abstracts,\\n�\\nnumber of vertices in the graph.is set to a third of the\\nDuring post-processing, all lexical units selected',\n",
              "  '�\\nnumber of vertices in the graph.\\nDuring post-processing, all lexical units selected\\nas potential keywords by the TextRank algorithm are\\nmarked in the text, and sequences of adjacent key-\\nwords are collapsed into a multi-word keyword. For\\ninstance, in the text Matlab code for plotting ambi-\\nguity functions, if both Matlab and code are selected\\nas potential keywords by TextRank, since they are\\nadjacent, they are collapsed into one single keyword\\nMatlab code.\\nFigure 2 shows a sample graph built for an abstract',\n",
              "  'Matlab code.\\nFigure 2 shows a sample graph built for an abstract\\nfrom our test collection. While the size of the ab-\\nstracts ranges from 50 to 350 words, with an average\\nsize of 120 words, we have deliberately selected a\\nvery small abstract for the purpose of illustration. For\\nthis example, the lexical units found to have higher\\n“importance” by the TextRank algorithm are (with\\nthe TextRank score indicated in parenthesis): num-\\nbers (1.46), inequations (1.45), linear (1.29), dio-\\nphantine (1.28), upper (0.99), bounds (0.99), strict\\n(0.77). Notice that this ranking is different than the\\none rendered by simple word frequencies. For the\\nsame text, a frequency approach provides the fol-\\nlowing top-ranked lexical units: systems (4), types\\n(3), solutions (3), minimal (3), linear (2), inequations\\n(2), algorithms (2). All other lexical units have a fre-\\nquency of 1, and therefore cannot be ranked, but only\\nlisted.\\n3.2\\nEvaluation',\n",
              "  'The data set used in the experiments is a collection\\nof 500 abstracts from the Inspec database, and the\\ncorresponding manually assigned keywords. This is\\nthe same test data set as used in the keyword ex-\\ntraction experiments reported in (Hulth, 2003). The\\nInspec abstracts are from journal papers from Com-\\nputer Science and Information Technology.\\nEach\\nabstract comes with two sets of keywords assigned\\nby professional indexers: controlled keywords, re-\\nstricted to a given thesaurus, and uncontrolled key-\\nwords, freely assigned by the indexers. We follow\\nthe evaluation approach from (Hulth, 2003), and use\\nthe uncontrolled set of keywords.\\nIn her experiments, Hulth is using a total of 2000',\n",
              "  'the uncontrolled set of keywords.\\nIn her experiments, Hulth is using a total of 2000\\nabstracts, divided into 1000 for training, 500 for de-\\nvelopment, and 500 for test2. Since our approach\\nis completely unsupervised, no training/development\\ndata is required, and we are only using the test docu-',\n",
              "  '2Many thanks to Anette Hulth for allowing us to run our al-\\ngorithm on the data set used in her keyword extraction exper-\\niments, and for making available the training/test/development\\ndata split.'],\n",
              " ['Table 1: Results for automatic keyword extraction using TextRank or supervised learning (Hulth, 2003)',\n",
              "  'ments for evaluation purposes.\\nThe results are evaluated using precision, recall,\\nand F-measure. Notice that the maximum recall that\\ncan be achieved on this collection is less than 100%,\\nsince indexers were not limited to keyword extrac-\\ntion – as our system is – but they were also allowed\\nto perform keyword generation, which eventually re-\\nsults in keywords that do not explicitly appear in the\\ntext.\\nFor comparison purposes, we are using the results',\n",
              "  'text.\\nFor comparison purposes, we are using the results\\nof the state-of-the-art keyword extraction system re-\\nported in (Hulth, 2003). Shortly, her system consists\\nof a supervised learning scheme that attempts to learn\\nhow to best extract keywords from a document, by\\nlooking at a set of four features that are determined\\nfor each “candidate” keyword: (1) within-document\\nfrequency, (2) collection frequency, (3) relative po-\\nsition of the first occurrence, (4) sequence of part of\\nspeech tags. These features are extracted from both\\ntraining and test data for all “candidate” keywords,\\nwhere a candidate keyword can be: Ngrams (uni-\\ngrams, bigrams, or trigrams extracted from the ab-\\nstracts), NP-chunks (noun phrases), patterns (a set of\\npart of speech patterns detected from the keywords\\nattached to the training abstracts). The learning sys-\\ntem is a rule induction system with bagging.\\nOur system consists of the TextRank approach de-',\n",
              "  'tem is a rule induction system with bagging.\\nOur system consists of the TextRank approach de-\\nscribed in Section 3.1, with a co-occurrence window-\\nsize set to two, three, five, or ten words. Table 1 lists\\nthe results obtained with TextRank, and the best re-\\nsults reported in (Hulth, 2003). For each method,\\nthe table lists the total number of keywords assigned,\\nthe mean number of keywords per abstract, the total\\nnumber of correct keywords, as evaluated against the\\nset of keywords assigned by professional indexers,\\nand the mean number of correct keywords. The table\\nalso lists precision, recall, and F-measure.',\n",
              "  'Discussion.\\nTextRank achieves the highest preci-\\nsion and F-measure across all systems, although the\\nrecall is not as high as in supervised methods – pos-',\n",
              "  'sibly due the limitation imposed by our approach on\\nthe number of keywords selected, which is not made\\nin the supervised system3. A larger window does not\\nseem to help – on the contrary, the larger the win-\\ndow, the lower the precision, probably explained by\\nthe fact that a relation between words that are further\\napart is not strong enough to define a connection in\\nthe text graph.\\nExperiments were performed with various syntac-',\n",
              "  'the text graph.\\nExperiments were performed with various syntac-\\ntic filters, including: all open class words, nouns and\\nadjectives, and nouns only, and the best performance\\nwas achieved with the filter that selects nouns and ad-\\njectives only. We have also experimented with a set-\\nting where no part of speech information was added\\nto the text, and all words - except a predefined list\\nof stopwords - were added to the graph.\\nThe re-\\nsults with this setting were significantly lower than\\nthe systems that consider part of speech information,\\nwhich corroborates with previous observations that\\nlinguistic information helps the process of keyword\\nextraction (Hulth, 2003).\\nExperiments were also performed with directed',\n",
              "  'extraction (Hulth, 2003).\\nExperiments were also performed with directed\\ngraphs, where a direction was set following the natu-\\nral flow of the text, e.g. one candidate keyword “rec-\\nommends” (and therefore has a directed arc to) the\\ncandidate keyword that follows in the text, keeping\\nthe restraint imposed by the co-occurrence relation.\\nWe have also tried the reversed direction, where a\\nlexical unit points to a previous token in the text.\\nTable 1 includes the results obtained with directed\\ngraphs for a co-occurrence window of 2. Regard-\\nless of the direction chosen for the arcs, results ob-\\ntained with directed graphs are worse than results ob-\\ntained with undirected graphs, which suggests that\\ndespite a natural flow in running text, there is no nat-\\nural “direction” that can be established between co-',\n",
              "  '3The fact that the supervised system does not have the ca-\\npability to set a cutoff threshold on the number of keywords,\\nbut it only makes a binary decision on each candidate word, has\\nthe downside of not allowing for a precision-recall curve, which\\nprohibits a comparison of such curves for the two methods.'],\n",
              " ['occurring words.\\nOverall, our TextRank system leads to an F-\\nmeasure higher than any of the previously proposed\\nsystems. Notice that TextRank is completely unsu-\\npervised, and unlike other supervised systems, it re-\\nlies exclusively on information drawn from the text\\nitself, which makes it easily portable to other text col-\\nlections, domains, and languages.',\n",
              "  '4\\nSentence Extraction\\nThe other TextRank application that we investigate\\nconsists of sentence extraction for automatic sum-\\nmarization. In a way, the problem of sentence extrac-\\ntion can be regarded as similar to keyword extraction,\\nsince both applications aim at identifying sequences\\nthat are more “representative” for the given text. In\\nkeyword extraction, the candidate text units consist\\nof words or phrases, whereas in sentence extraction,\\nwe deal with entire sentences. TextRank turns out to\\nbe well suited for this type of applications, since it\\nallows for a ranking over text units that is recursively\\ncomputed based on information drawn from the en-\\ntire text.\\n4.1\\nTextRank for Sentence Extraction',\n",
              "  '4.1\\nTextRank for Sentence Extraction\\nTo apply TextRank, we first need to build a graph as-\\nsociated with the text, where the graph vertices are\\nrepresentative for the units to be ranked. For the task\\nof sentence extraction, the goal is to rank entire sen-\\ntences, and therefore a vertex is added to the graph\\nfor each sentence in the text.\\nThe co-occurrence relation used for keyword ex-',\n",
              "  'for each sentence in the text.\\nThe co-occurrence relation used for keyword ex-\\ntraction cannot be applied here, since the text units in\\nconsideration are significantly larger than one or few\\nwords, and “co-occurrence” is not a meaningful rela-\\ntion for such large contexts. Instead, we are defining\\na different relation, which determines a connection\\nbetween two sentences if there is a “similarity” re-\\nlation between them, where “similarity” is measured\\nas a function of their content overlap. Such a rela-\\ntion between two sentences can be seen as a process\\nof “recommendation”: a sentence that addresses cer-\\ntain concepts in a text, gives the reader a “recom-\\nmendation” to refer to other sentences in the text that\\naddress the same concepts, and therefore a link can\\nbe drawn between any two such sentences that share\\ncommon content.\\nThe overlap of two sentences can be determined',\n",
              "  'common content.\\nThe overlap of two sentences can be determined\\nsimply as the number of common tokens between\\nthe lexical representations of the two sentences, or\\nit can be run through syntactic filters, which only\\ncount words of a certain syntactic category, e.g. all\\nopen class words, nouns and verbs, etc. Moreover,\\nto avoid promoting long sentences, we are using a\\nnormalization factor, and divide the content overlap'],\n",
              " ['of two sentences with the length of each sentence.\\nFormally, given two sentences\\n�\\n� and\\n�\\nsentence being represented by the set of� , with a\\n�\\n� words\\nthat appear in the sentence:\\n�\\n�\\n�\\n�\\n�\\n�\\n���\\n�\\n�\\n����\\n���\\n��\\n$ ,\\nthe similarity of\\n�\\n� and\\n�� is defined as:',\n",
              "  '������������������K���\\n�\\n���\\n�\\n�2�\\n4\\n!#\"�$�%\\n�\\n�\\n$\\n�\\n&�\\'\\n!#\"�$�%\\n�\\n�\\n4\\n�\\n&\\nOther sentence similarity measures, such as string\\nkernels, cosine similarity, longest common subse-\\nquence, etc. are also possible, and we are currently\\nevaluating their impact on the summarization perfor-\\nmance.\\nThe resulting graph is highly connected, with a',\n",
              "  'mance.\\nThe resulting graph is highly connected, with a\\nweight associated with each edge, indicating the\\nstrength of the connections established between var-\\nious sentence pairs in the text. The text is therefore\\nrepresented as a weighted graph, and consequently\\nwe are using the weighted graph-based ranking for-\\nmula introduced in Section 2.2.\\nAfter the ranking algorithm is run on the graph,',\n",
              "  'mula introduced in Section 2.2.\\nAfter the ranking algorithm is run on the graph,\\nsentences are sorted in reversed order of their score,\\nand the top ranked sentences are selected for inclu-\\nsion in the summary.\\nFigure 3 shows a text sample, and the associated',\n",
              "  'sion in the summary.\\nFigure 3 shows a text sample, and the associated\\nweighted graph constructed for this text. The fig-\\nure also shows sample weights attached to the edges\\nconnected to vertex 94, and the final TextRank score\\ncomputed for each sentence. The sentences with the\\nhighest rank are selected for inclusion in the abstract.\\nFor this sample article, the sentences with id-s 9, 15,\\n16, 18 are extracted, resulting in a summary of about\\n100 words, which according to automatic evaluation\\nmeasures, is ranked the second among summaries\\nproduced by 15 other systems (see Section 4.2 for\\nevaluation methodology).\\n4.2\\nEvaluation',\n",
              "  '4.2\\nEvaluation\\nWe evaluate the TextRank sentence extraction algo-\\nrithm on a single-document summarization task, us-\\ning 567 news articles provided during the Document\\nUnderstanding Evaluations 2002 (DUC, 2002). For\\neach article, TextRank generates an 100-words sum-\\nmary — the task undertaken by other systems partic-\\nipating in this single document summarization task.\\nFor evaluation, we are using the ROUGE evalu-',\n",
              "  'ipating in this single document summarization task.\\nFor evaluation, we are using the ROUGE evalu-\\nation toolkit, which is a method based on Ngram\\nstatistics, found to be highly correlated with hu-\\nman evaluations (Lin and Hovy, 2003). Two manu-\\nally produced reference summaries are provided, and\\nused in the evaluation process5.',\n",
              "  '4Weights are listed to the right or above the edge they cor-\\nrespond to. Similar weights are computed for each edge in the\\ngraph, but are not displayed due to space restrictions.\\n5ROUGE is available at http://www.isi.edu/˜cyl/ROUGE/.',\n",
              "  'raph, but are not displayed due to space restrictions.\\n5ROUGE is available at http://www.isi.edu/˜cyl/ROUGE/.',\n",
              "  'Fifteen different systems participated in this task,\\nand we compare the performance of TextRank with\\nthe top five performing systems, as well as with the\\nbaseline proposed by the DUC evaluators – consist-\\ning of a 100-word summary constructed by taking\\nthe first sentences in each article. Table 2 shows the\\nresults obtained on this data set of 567 news articles,\\nincluding the results for TextRank (shown in bold),\\nthe baseline, and the results of the top five perform-\\ning systems in the DUC 2002 single document sum-\\nmarization task (DUC, 2002).',\n",
              "  'Table 2: Results for single document summarization:\\nTextRank, top 5 (out of 15) DUC 2002 systems, and\\nbaseline. Evaluation takes into account (a) all words;\\n(b) stemmed words; (c) stemmed words, and no stop-\\nwords.',\n",
              "  'Discussion.\\nTextRank succeeds in identifying the\\nmost important sentences in a text based on infor-\\nmation exclusively drawn from the text itself. Un-\\nlike other supervised systems, which attempt to learn\\nwhat makes a good summary by training on collec-\\ntions of summaries built for other articles, TextRank\\nis fully unsupervised, and relies only on the given\\ntext to derive an extractive summary, which repre-\\nsents a summarization model closer to what humans\\nare doing when producing an abstract for a given\\ndocument.\\nNotice that TextRank goes beyond the sentence',\n",
              "  'document.\\nNotice that TextRank goes beyond the sentence\\n“connectivity” in a text. For instance, sentence 15 in\\nthe example provided in Figure 3 would not be iden-\\ntified as “important” based on the number of connec-\\ntions it has with other vertices in the graph, but it is\\nidentified as “important” by TextRank (and by hu-\\nmans – see the reference summaries displayed in the\\nsame figure).\\nAnother important aspect of TextRank is that it',\n",
              "  'same figure).\\nAnother important aspect of TextRank is that it\\ngives a ranking over all sentences in a text – which\\nmeans that it can be easily adapted to extracting\\nvery short summaries (headlines consisting of one',\n",
              "  'The evaluation is done using the Ngram(1,1) setting of ROUGE,\\nwhich was found to have the highest correlation with human\\njudgments, at a confidence level of 95%.\\nOnly the first 100\\nwords in each summary are considered.'],\n",
              " ['sentence), or longer more explicative summaries,\\nconsisting of more than 100 words.\\nWe are also\\ninvestigating combinations of keyphrase and sen-\\ntence extraction techniques as a method for building\\nshort/long summaries.\\nFinally, another advantage of TextRank over previ-',\n",
              "  'short/long summaries.\\nFinally, another advantage of TextRank over previ-\\nously proposed methods for building extractive sum-\\nmaries is the fact that it does not require training cor-\\npora, which makes it easily adaptable to other lan-\\nguages or domains.',\n",
              "  '5\\nWhy TextRank Works\\nIntuitively, TextRank works well because it does not\\nonly rely on the local context of a text unit (vertex),\\nbut rather it takes into account information recur-\\nsively drawn from the entire text (graph).\\nThrough the graphs it builds on texts, TextRank',\n",
              "  'sively drawn from the entire text (graph).\\nThrough the graphs it builds on texts, TextRank\\nidentifies connections between various entities in a\\ntext, and implements the concept of recommenda-\\ntion.\\nA text unit recommends other related text\\nunits, and the strength of the recommendation is re-\\ncursively computed based on the importance of the\\nunits making the recommendation. For instance, in\\nthe keyphrase extraction application, co-occurring\\nwords recommend each other as important, and it is\\nthe common context that enables the identification of\\nconnections between words in text. In the process of\\nidentifying important sentences in a text, a sentence\\nrecommends another sentence that addresses similar\\nconcepts as being useful for the overall understand-\\ning of the text. The sentences that are highly recom-\\nmended by other sentences in the text are likely to\\nbe more informative for the given text, and will be\\ntherefore given a higher score.\\nAn analogy can be also drawn with PageRank’s',\n",
              "  'therefore given a higher score.\\nAn analogy can be also drawn with PageRank’s\\n“random surfer model”, where a user surfs the Web\\nby following links from any given Web page. In the\\ncontext of text modeling, TextRank implements what\\nwe refer to as “text surfing”, which relates to the con-\\ncept of text cohesion (Halliday and Hasan, 1976):\\nfrom a certain concept\\n�\\nin a text, we are likely to\\n“follow” links to connected concepts – that is, con-\\ncepts that have a relation with the current concept\\n(be that a lexical or semantic relation). This also re-�\\nlates to the “knitting” phenomenon (Hobbs, 1974):\\nfacts associated with words are shared in different\\nparts of the discourse, and such relationships serve\\nto “knit the discourse together”.\\nThrough its iterative mechanism, TextRank goes',\n",
              "  'to “knit the discourse together”.\\nThrough its iterative mechanism, TextRank goes\\nbeyond simple graph connectivity, and it is able to\\nscore text units based also on the “importance” of\\nother text units they link to. The text units selected by\\nTextRank for a given application are the ones most\\nrecommended by related text units in the text, with\\npreference given to the recommendations made by',\n",
              "  'most influential ones, i.e. the ones that are in turn\\nhighly recommended by other related units. The un-\\nderlying hypothesis is that in a cohesive text frag-\\nment, related text units tend to form a “Web” of con-\\nnections that approximates the model humans build\\nabout a given context in the process of discourse un-\\nderstanding.',\n",
              "  '6\\nConclusions\\nIn this paper, we introduced TextRank – a graph-\\nbased ranking model for text processing, and show\\nhow it can be successfully used for natural language\\napplications.\\nIn particular, we proposed and eval-\\nuated two innovative unsupervised approaches for\\nkeyword and sentence extraction, and showed that\\nthe accuracy achieved by TextRank in these applica-\\ntions is competitive with that of previously proposed\\nstate-of-the-art algorithms. An important aspect of\\nTextRank is that it does not require deep linguistic\\nknowledge, nor domain or language specific anno-\\ntated corpora, which makes it highly portable to other\\ndomains, genres, or languages.\\nReferences']]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Er0kA-C-gs",
        "outputId": "716ec5e8-66d9-476b-a461-e1c396ec9ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "of two sentences with the length of each sentence. Formally, given two sentences and sentence being represented by the set of , with a words that appear in the sentence: $ , the similarity of and is defined as:', ' K 2 4 !#\" $ % $ & ' !#\" $ % 4 & Other sentence similarity measures, such as string kernels, cosine similarity, longest common subse- quence, etc. are also possible, and we are currently evaluating their impact on the summarization perfor- mance. The resulting graph is highly connected\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove non-ASCII characters\n",
        "    ascii_text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "\n",
        "    # Replace newline characters and multiple spaces with a single space\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', ascii_text).strip()\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Sample extracted text\n",
        "text = '''of two sentences with the length of each sentence.\\nFormally, given two sentences\\n�\\n� and\\n�\\nsentence being represented by the set of� , with a\\n�\\n� words\\nthat appear in the sentence:\\n�\\n�\\n�\\n�\\n�\\n�\\n���\\n�\\n�\\n����\\n���\\n��\\n$ ,\\nthe similarity of\\n�\\n� and\\n�� is defined as:',\n",
        "'������������������K���\\n�\\n���\\n�\\n�2�\\n4\\n!#\"�$�%\\n�\\n�\\n$\\n�\\n&�\\'\\n!#\"�$�%\\n�\\n�\\n4\\n�\\n&\\nOther sentence similarity measures, such as string\\nkernels, cosine similarity, longest common subse-\\nquence, etc. are also possible, and we are currently\\nevaluating their impact on the summarization perfor-\\nmance.\\nThe resulting graph is highly connected'''\n",
        "\n",
        "cleaned_text = clean_text(text)\n",
        "print(cleaned_text)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNjn5zsGkREiq9SLGznMPk",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}